{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined playlists CSV saved to playlists.csv\n",
      "Combined tracks CSV saved to tracks.csv\n",
      "Updated playlists CSV with processed 'tracks' column saved.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def combine_and_encode_tracks(tracks_folder, tracks_output_csv, playlist_mapping=None):\n",
    "    \"\"\"\n",
    "    Combine all track Parquet files into one DataFrame and encode the 'track_uri'\n",
    "    column into a new 'track_idx' column.\n",
    "    Optionally, process the 'inside_playlists' column (a list of pids) to convert them\n",
    "    to their corresponding playlist_idx using playlist_mapping and remove duplicates.\n",
    "    \n",
    "    Returns the combined DataFrame and a mapping dictionary from track_uri to track_idx.\n",
    "    \"\"\"\n",
    "    dfs = []\n",
    "    for file in os.listdir(tracks_folder):\n",
    "        if file.endswith(\".parquet\"):\n",
    "            file_path = os.path.join(tracks_folder, file)\n",
    "            df = pd.read_parquet(file_path)\n",
    "            dfs.append(df)\n",
    "            \n",
    "    if dfs:\n",
    "        combined_df = pd.concat(dfs, ignore_index=True)\n",
    "        encoder = LabelEncoder()\n",
    "        combined_df['track_idx'] = encoder.fit_transform(combined_df['track_uri'])\n",
    "        \n",
    "        # Process 'inside_playlists' if playlist_mapping is provided.\n",
    "        if playlist_mapping is not None and 'inside_playlists' in combined_df.columns:\n",
    "            def transform_inside_playlists(pid_list):\n",
    "                # Map each pid to its playlist_idx, defaulting to -1 if not found.\n",
    "                mapped = [playlist_mapping.get(pid, -1) for pid in pid_list]\n",
    "                # Remove duplicates while preserving order\n",
    "                seen = set()\n",
    "                unique = []\n",
    "                for item in mapped:\n",
    "                    if item not in seen:\n",
    "                        unique.append(item)\n",
    "                        seen.add(item)\n",
    "                return unique\n",
    "            combined_df['inside_playlists'] = combined_df['inside_playlists'].apply(transform_inside_playlists)\n",
    "        \n",
    "        combined_df.to_csv(tracks_output_csv, index=False)\n",
    "        print(f\"Combined tracks CSV saved to {tracks_output_csv}\")\n",
    "        track_mapping = dict(zip(combined_df['track_uri'], combined_df['track_idx']))\n",
    "        return combined_df, track_mapping\n",
    "    else:\n",
    "        print(\"No Parquet files found in the tracks folder.\")\n",
    "        return None, {}\n",
    "\n",
    "def process_playlist_tracks(df, track_mapping):\n",
    "    \"\"\"\n",
    "    Replace the 'tracks' column in a playlist DataFrame with a dictionary that maps\n",
    "    each track's position (from the 'pos' field within each track details) to its\n",
    "    corresponding track index from the track_mapping.\n",
    "    \n",
    "    Each element in the 'tracks' list is expected to be a dictionary with at least:\n",
    "        - 'track_uri': the identifier for the track.\n",
    "        - 'pos': the position of the track in the playlist.\n",
    "    \"\"\"\n",
    "    if 'tracks' in df.columns:\n",
    "        def transform_tracks(tracks):\n",
    "            return {str(track['pos']): str(track_mapping.get(track['track_uri'], -1)) \n",
    "                    for track in tracks}\n",
    "        df['tracks'] = df['tracks'].apply(transform_tracks)\n",
    "    return df\n",
    "\n",
    "def combine_and_encode_playlists(playlists_folder, playlists_output_csv):\n",
    "    \"\"\"\n",
    "    Combine all playlist Parquet files into one DataFrame, encode the primary key 'pid'\n",
    "    into a new column 'playlist_idx' using LabelEncoder on the combined data, and process\n",
    "    the 'tracks' column to replace it with a dictionary mapping track position to track index.\n",
    "    \n",
    "    Returns the combined DataFrame and a mapping from pid to playlist_idx.\n",
    "    \"\"\"\n",
    "    dfs = []\n",
    "    for file in os.listdir(playlists_folder):\n",
    "        if file.endswith(\".parquet\"):\n",
    "            file_path = os.path.join(playlists_folder, file)\n",
    "            df = pd.read_parquet(file_path)\n",
    "            dfs.append(df)\n",
    "    \n",
    "    if dfs:\n",
    "        combined_df = pd.concat(dfs, ignore_index=True)\n",
    "        \n",
    "        # Apply LabelEncoder on the combined DataFrame for the playlist primary key 'pid'\n",
    "        encoder = LabelEncoder()\n",
    "        combined_df['playlist_idx'] = encoder.fit_transform(combined_df['pid'])\n",
    "        \n",
    "        # Process the 'tracks' column using the provided track_mapping later in this function.\n",
    "        # Note: This will be done after we obtain the track mapping.\n",
    "        \n",
    "        combined_df.to_csv(playlists_output_csv, index=False)\n",
    "        print(f\"Combined playlists CSV saved to {playlists_output_csv}\")\n",
    "        playlist_mapping = dict(zip(combined_df['pid'], combined_df['playlist_idx']))\n",
    "        return combined_df, playlist_mapping\n",
    "    else:\n",
    "        print(\"No Parquet files found in the playlists folder.\")\n",
    "        return None, {}\n",
    "\n",
    "# Example usage:\n",
    "\n",
    "# First, combine and encode playlists to generate a mapping from pid to playlist_idx.\n",
    "playlists_folder = \"parquet datasets/playlists\"\n",
    "playlists_output_csv = \"playlists.csv\"\n",
    "playlists_df, playlist_mapping = combine_and_encode_playlists(playlists_folder, playlists_output_csv)\n",
    "\n",
    "# Next, combine and encode tracks. Use the playlist_mapping to process the 'inside_playlists' column.\n",
    "tracks_folder = \"parquet datasets/tracks\"\n",
    "tracks_output_csv = \"tracks.csv\"\n",
    "tracks_df, track_mapping = combine_and_encode_tracks(tracks_folder, tracks_output_csv, playlist_mapping)\n",
    "\n",
    "# Now, if needed, you can further process the playlists to update their 'tracks' column.\n",
    "# For example, if you want to update the 'tracks' column to map positions to track_idx:\n",
    "if playlists_df is not None:\n",
    "    playlists_df = process_playlist_tracks(playlists_df, track_mapping)\n",
    "    playlists_df.to_csv(playlists_output_csv, index=False)\n",
    "    print(\"Updated playlists CSV with processed 'tracks' column saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>collaborative</th>\n",
       "      <th>pid</th>\n",
       "      <th>modified_at</th>\n",
       "      <th>num_tracks</th>\n",
       "      <th>num_albums</th>\n",
       "      <th>num_followers</th>\n",
       "      <th>tracks</th>\n",
       "      <th>num_edits</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>num_artists</th>\n",
       "      <th>description</th>\n",
       "      <th>playlist_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Winter 16/17</td>\n",
       "      <td>False</td>\n",
       "      <td>656605</td>\n",
       "      <td>2017-10-31</td>\n",
       "      <td>116</td>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "      <td>{'0': '56159', '1': '158741', '2': '130035', '...</td>\n",
       "      <td>84</td>\n",
       "      <td>27464949</td>\n",
       "      <td>112</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Country</td>\n",
       "      <td>False</td>\n",
       "      <td>43568</td>\n",
       "      <td>2017-10-31</td>\n",
       "      <td>193</td>\n",
       "      <td>114</td>\n",
       "      <td>1</td>\n",
       "      <td>{'0': '220590', '1': '199180', '2': '108648', ...</td>\n",
       "      <td>73</td>\n",
       "      <td>42549856</td>\n",
       "      <td>68</td>\n",
       "      <td>NaN</td>\n",
       "      <td>885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FALL</td>\n",
       "      <td>False</td>\n",
       "      <td>892061</td>\n",
       "      <td>2017-10-31</td>\n",
       "      <td>51</td>\n",
       "      <td>48</td>\n",
       "      <td>2</td>\n",
       "      <td>{'0': '167186', '1': '31002', '2': '117854', '...</td>\n",
       "      <td>34</td>\n",
       "      <td>10589174</td>\n",
       "      <td>47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>happy mix</td>\n",
       "      <td>False</td>\n",
       "      <td>284411</td>\n",
       "      <td>2017-10-31</td>\n",
       "      <td>75</td>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "      <td>{'0': '217906', '1': '95923', '2': '206234', '...</td>\n",
       "      <td>60</td>\n",
       "      <td>33358703</td>\n",
       "      <td>66</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hype it up</td>\n",
       "      <td>False</td>\n",
       "      <td>44918</td>\n",
       "      <td>2017-10-31</td>\n",
       "      <td>114</td>\n",
       "      <td>83</td>\n",
       "      <td>1</td>\n",
       "      <td>{'0': '36171', '1': '75724', '2': '68192', '3'...</td>\n",
       "      <td>57</td>\n",
       "      <td>27651175</td>\n",
       "      <td>52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>924</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           name  collaborative     pid modified_at  num_tracks  num_albums  \\\n",
       "0  Winter 16/17          False  656605  2017-10-31         116         115   \n",
       "1      Country           False   43568  2017-10-31         193         114   \n",
       "2         FALL           False  892061  2017-10-31          51          48   \n",
       "3     happy mix          False  284411  2017-10-31          75          72   \n",
       "4    Hype it up          False   44918  2017-10-31         114          83   \n",
       "\n",
       "   num_followers                                             tracks  \\\n",
       "0              1  {'0': '56159', '1': '158741', '2': '130035', '...   \n",
       "1              1  {'0': '220590', '1': '199180', '2': '108648', ...   \n",
       "2              2  {'0': '167186', '1': '31002', '2': '117854', '...   \n",
       "3              1  {'0': '217906', '1': '95923', '2': '206234', '...   \n",
       "4              1  {'0': '36171', '1': '75724', '2': '68192', '3'...   \n",
       "\n",
       "   num_edits  duration_ms  num_artists description  playlist_idx  \n",
       "0         84     27464949          112         NaN         13122  \n",
       "1         73     42549856           68         NaN           885  \n",
       "2         34     10589174           47         NaN         17788  \n",
       "3         60     33358703           66         NaN          5836  \n",
       "4         57     27651175           52         NaN           924  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "playlists = pd.read_csv(playlists_output_csv)\n",
    "print(len(playlists))\n",
    "playlists.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "252236\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_uri</th>\n",
       "      <th>album_name</th>\n",
       "      <th>album_uri</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>artist_uri</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>pos</th>\n",
       "      <th>track_name</th>\n",
       "      <th>inside_playlists</th>\n",
       "      <th>track_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spotify:track:2sywvGUBuSuYICHHKOElSn</td>\n",
       "      <td>Knock Madness</td>\n",
       "      <td>spotify:album:16SMGvTZrwtiJ132g69toP</td>\n",
       "      <td>Hopsin</td>\n",
       "      <td>spotify:artist:7EWU4FhUJM1sZQgQKdENeT</td>\n",
       "      <td>211573</td>\n",
       "      <td>106</td>\n",
       "      <td>Nollie Tre Flip</td>\n",
       "      <td>[9885, 11157, 4959, 18044]</td>\n",
       "      <td>93755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spotify:track:7n1y18wPhZv5YxpR6nFBck</td>\n",
       "      <td>Knock Madness</td>\n",
       "      <td>spotify:album:16SMGvTZrwtiJ132g69toP</td>\n",
       "      <td>Hopsin</td>\n",
       "      <td>spotify:artist:7EWU4FhUJM1sZQgQKdENeT</td>\n",
       "      <td>257600</td>\n",
       "      <td>107</td>\n",
       "      <td>I Need Help</td>\n",
       "      <td>[9885, 774, 11157, 16421, 15329, 17621, 2799, ...</td>\n",
       "      <td>245549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spotify:track:1zZXXOfcYKJbUh494VmGVB</td>\n",
       "      <td>Knock Madness</td>\n",
       "      <td>spotify:album:16SMGvTZrwtiJ132g69toP</td>\n",
       "      <td>Hopsin</td>\n",
       "      <td>spotify:artist:7EWU4FhUJM1sZQgQKdENeT</td>\n",
       "      <td>231493</td>\n",
       "      <td>108</td>\n",
       "      <td>Rip Your Heart Out (feat. Tech N9ne)</td>\n",
       "      <td>[9885, 16421, 3046, 5920, 1662, 17621, 14239, ...</td>\n",
       "      <td>64890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spotify:track:4lDRCZho3GlmRqOJRjmLfE</td>\n",
       "      <td>Bout the Business</td>\n",
       "      <td>spotify:album:6kVdsufIniV3hlXSxKxax2</td>\n",
       "      <td>Hopsin</td>\n",
       "      <td>spotify:artist:7EWU4FhUJM1sZQgQKdENeT</td>\n",
       "      <td>272360</td>\n",
       "      <td>110</td>\n",
       "      <td>Bout the Business</td>\n",
       "      <td>[9885, 774, 4577, 19798, 19041, 12834, 12320, ...</td>\n",
       "      <td>154041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spotify:track:5wWDfRF7NQKMx8ZPfrhBwa</td>\n",
       "      <td>Funk Volume 2013 - Single</td>\n",
       "      <td>spotify:album:6pCCQ7R7J4N2femfQVbFg2</td>\n",
       "      <td>Hopsin</td>\n",
       "      <td>spotify:artist:7EWU4FhUJM1sZQgQKdENeT</td>\n",
       "      <td>313195</td>\n",
       "      <td>112</td>\n",
       "      <td>Funk Volume 2013</td>\n",
       "      <td>[9885, 5920, 17092]</td>\n",
       "      <td>192527</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              track_uri                 album_name  \\\n",
       "0  spotify:track:2sywvGUBuSuYICHHKOElSn              Knock Madness   \n",
       "1  spotify:track:7n1y18wPhZv5YxpR6nFBck              Knock Madness   \n",
       "2  spotify:track:1zZXXOfcYKJbUh494VmGVB              Knock Madness   \n",
       "3  spotify:track:4lDRCZho3GlmRqOJRjmLfE          Bout the Business   \n",
       "4  spotify:track:5wWDfRF7NQKMx8ZPfrhBwa  Funk Volume 2013 - Single   \n",
       "\n",
       "                              album_uri artist_name  \\\n",
       "0  spotify:album:16SMGvTZrwtiJ132g69toP      Hopsin   \n",
       "1  spotify:album:16SMGvTZrwtiJ132g69toP      Hopsin   \n",
       "2  spotify:album:16SMGvTZrwtiJ132g69toP      Hopsin   \n",
       "3  spotify:album:6kVdsufIniV3hlXSxKxax2      Hopsin   \n",
       "4  spotify:album:6pCCQ7R7J4N2femfQVbFg2      Hopsin   \n",
       "\n",
       "                              artist_uri  duration_ms  pos  \\\n",
       "0  spotify:artist:7EWU4FhUJM1sZQgQKdENeT       211573  106   \n",
       "1  spotify:artist:7EWU4FhUJM1sZQgQKdENeT       257600  107   \n",
       "2  spotify:artist:7EWU4FhUJM1sZQgQKdENeT       231493  108   \n",
       "3  spotify:artist:7EWU4FhUJM1sZQgQKdENeT       272360  110   \n",
       "4  spotify:artist:7EWU4FhUJM1sZQgQKdENeT       313195  112   \n",
       "\n",
       "                             track_name  \\\n",
       "0                       Nollie Tre Flip   \n",
       "1                           I Need Help   \n",
       "2  Rip Your Heart Out (feat. Tech N9ne)   \n",
       "3                     Bout the Business   \n",
       "4                      Funk Volume 2013   \n",
       "\n",
       "                                    inside_playlists  track_idx  \n",
       "0                         [9885, 11157, 4959, 18044]      93755  \n",
       "1  [9885, 774, 11157, 16421, 15329, 17621, 2799, ...     245549  \n",
       "2  [9885, 16421, 3046, 5920, 1662, 17621, 14239, ...      64890  \n",
       "3  [9885, 774, 4577, 19798, 19041, 12834, 12320, ...     154041  \n",
       "4                                [9885, 5920, 17092]     192527  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracks = pd.read_csv(tracks_output_csv)\n",
    "print(len(tracks))\n",
    "tracks.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
