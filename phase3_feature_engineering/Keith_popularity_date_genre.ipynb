{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SPOTIPY_CLIENT_ID: fe85ab3c7e504bbf92ebb2bf84003d9a\n",
      "SPOTIPY_CLIENT_SECRET: 9862ea******\n",
      "Loaded dataset from: /Users/xavierhua/Documents/GitHub/bt4222grp9/preliminary datasets/all_songs_with_or_without_lyrics.parquet\n",
      "Unique track URIs: 252236 | Unique album names: 105931\n",
      "Previously processed tracks: 203541\n",
      "Previously processed albums: 0\n",
      "Starting track popularity extraction | Remaining track batches: 983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining track batches: 983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Track Popularity:   0%|          | 0/983 [00:00<?, ?it/s]Fetching track popularity for batch (size=50): ['4BOffopj7gh2lTmJK0i6pH', '4rx79VDJizteqSOT7PQaJl', '32KK5ssfN5vuKRaCsfa63R', '1jPTgvMhaSoRAOD9COQm8l', '25XUnsWG9Bv08BVQP3Sze1', '2vGkhLDyTI3RVu1eKIQVeh', '3AlLUDEBD7teu96ozLarml', '7HbJiOw9TePjIcvvHCeWRc', '3PaUIDgMkbY8otG3XUBQek', '4Vwj4sbwakE8oCmqJ3ufki', '7q0ZcgGz9DSjadnEOe5Nsk', '60kbEtzqPb2l5tXwKFWwYQ', '722etYXeNBNmfsR69z27al', '00WFoR7tPga5Wj92MSR3eD', '2eq9aw5ZZIuRswW9fy5PKE', '6BNymc6C7PlRwBzgZBm5dk', '4h4tD5u0YMrHRh47sIy1Wl', '4itZtZUPOT2WkXO6vpeYqD', '5iAQ8dHSRTxZBJvjQvcR94', '3sI59rkOqPPZju0sh5K8il', '0qeG7GDVR7DXOgQVJkIJUB', '41JWvOS6vhn2uANnUsKVEG', '7gznAeluIdC6GGRSP16dil', '7HS8WT7Qf7OUKcQhW6zF4h', '21JiHTl5br1RJ3QRFaF4pa', '13D9T7wQr4m2XFA2OxQr7x', '2sQF0ZgDVbStYLQ1nKl4WL', '6Tllev6fw9tXOodmoAsIZC', '6d4PPwLXfs7dxpOt7NiP7K', '2MvBQVGPEEMQixRYu3HWea', '0t8OGYVNHQmO4VbJS3L64L', '6T6prTkN0PgnGPdW7lZ7Jv', '3RqMqrZ4dKSiGX7vBiS7L6', '2mNJADsO7l51mVhoCEESz7', '5yK0lEffT7BqplloPOrg2g', '2fBOS1NT8dYFrypecpjoOS', '3vc7vVDMQtcQ2bFMURz7pp', '2kYfoMA7U0x1eAZev268T0', '24MXVlAbvjmnwXlM5n8xvH', '0cexJwxzzgG2ztNgwB6JpR', '5KXKOO30cuhTILH0kGPwdf', '183yC8sfatJuZdJecceujV', '6NY4RcJyphehUe6TtFb1xh', '6wDfZpMZ2ljFCoSozE2gka', '3iXR5Hhw6z6oYe75Buectf', '14PEigdOtEYZayJ68cTey4', '3AQBB7cNkDz3pEyWehsBbE', '6yXxIuw7HOcBBD0BB9Z4BR', '6uWvMsU36wN3yQNpeN9jit', '5mbP34n4pUbcNVbFMYefHM']\n",
      "Your application has reached a rate/request limit. Retry will occur after: 79358\n",
      "Fetching Track Popularity:   0%|          | 0/983 [00:12<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 193\u001b[39m\n\u001b[32m    190\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRemaining track batches: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(remaining_track_batches)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    192\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m tqdm(remaining_track_batches, desc=\u001b[33m\"\u001b[39m\u001b[33mFetching Track Popularity\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m193\u001b[39m     track_popularity_dict.update(\u001b[43mfetch_track_popularity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    195\u001b[39m     \u001b[38;5;66;03m# Save progress every 500 records processed\u001b[39;00m\n\u001b[32m    196\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(track_popularity_dict) % \u001b[32m500\u001b[39m < \u001b[32m50\u001b[39m:  \u001b[38;5;66;03m# near multiples of 500\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 120\u001b[39m, in \u001b[36mfetch_track_popularity\u001b[39m\u001b[34m(track_batch)\u001b[39m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m         response = \u001b[43msp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtracks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrack_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    121\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m {track[\u001b[33m\"\u001b[39m\u001b[33mid\u001b[39m\u001b[33m\"\u001b[39m]: track[\u001b[33m\"\u001b[39m\u001b[33mpopularity\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m track \u001b[38;5;129;01min\u001b[39;00m response[\u001b[33m\"\u001b[39m\u001b[33mtracks\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m track}\n\u001b[32m    123\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m spotipy.SpotifyException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/bt4222grp9/.venv/lib/python3.13/site-packages/spotipy/client.py:383\u001b[39m, in \u001b[36mSpotify.tracks\u001b[39m\u001b[34m(self, tracks, market)\u001b[39m\n\u001b[32m    375\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\" returns a list of tracks given a list of track IDs, URIs, or URLs\u001b[39;00m\n\u001b[32m    376\u001b[39m \n\u001b[32m    377\u001b[39m \u001b[33;03m    Parameters:\u001b[39;00m\n\u001b[32m    378\u001b[39m \u001b[33;03m        - tracks - a list of spotify URIs, URLs or IDs. Maximum: 50 IDs.\u001b[39;00m\n\u001b[32m    379\u001b[39m \u001b[33;03m        - market - an ISO 3166-1 alpha-2 country code.\u001b[39;00m\n\u001b[32m    380\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    382\u001b[39m tlist = [\u001b[38;5;28mself\u001b[39m._get_id(\u001b[33m\"\u001b[39m\u001b[33mtrack\u001b[39m\u001b[33m\"\u001b[39m, t) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m tracks]\n\u001b[32m--> \u001b[39m\u001b[32m383\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtracks/?ids=\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m,\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtlist\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmarket\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmarket\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/bt4222grp9/.venv/lib/python3.13/site-packages/spotipy/client.py:324\u001b[39m, in \u001b[36mSpotify._get\u001b[39m\u001b[34m(self, url, args, payload, **kwargs)\u001b[39m\n\u001b[32m    321\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m args:\n\u001b[32m    322\u001b[39m     kwargs.update(args)\n\u001b[32m--> \u001b[39m\u001b[32m324\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_internal_call\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mGET\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpayload\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/bt4222grp9/.venv/lib/python3.13/site-packages/spotipy/client.py:269\u001b[39m, in \u001b[36mSpotify._internal_call\u001b[39m\u001b[34m(self, method, url, payload, params)\u001b[39m\n\u001b[32m    265\u001b[39m logger.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSending \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmethod\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m with Params: \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    266\u001b[39m              \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs.get(\u001b[33m'\u001b[39m\u001b[33mparams\u001b[39m\u001b[33m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m Headers: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mheaders\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m and Body: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs.get(\u001b[33m'\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m'\u001b[39m)\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    268\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m269\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_session\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    270\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    271\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequests_timeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\n\u001b[32m    272\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    274\u001b[39m     response.raise_for_status()\n\u001b[32m    275\u001b[39m     results = response.json()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/bt4222grp9/.venv/lib/python3.13/site-packages/requests/sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    584\u001b[39m send_kwargs = {\n\u001b[32m    585\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m: timeout,\n\u001b[32m    586\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m: allow_redirects,\n\u001b[32m    587\u001b[39m }\n\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/bt4222grp9/.venv/lib/python3.13/site-packages/requests/sessions.py:703\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    700\u001b[39m start = preferred_clock()\n\u001b[32m    702\u001b[39m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m703\u001b[39m r = \u001b[43madapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[32m    706\u001b[39m elapsed = preferred_clock() - start\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/bt4222grp9/.venv/lib/python3.13/site-packages/requests/adapters.py:667\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    664\u001b[39m     timeout = TimeoutSauce(connect=timeout, read=timeout)\n\u001b[32m    666\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m667\u001b[39m     resp = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    668\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    669\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    670\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    671\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    672\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    673\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    674\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    675\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    676\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    677\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    678\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    679\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    681\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    682\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request=request)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/bt4222grp9/.venv/lib/python3.13/site-packages/urllib3/connectionpool.py:940\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    937\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n\u001b[32m    939\u001b[39m response.drain_conn()\n\u001b[32m--> \u001b[39m\u001b[32m940\u001b[39m \u001b[43mretries\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    941\u001b[39m log.debug(\u001b[33m\"\u001b[39m\u001b[33mRetry: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m, url)\n\u001b[32m    942\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.urlopen(\n\u001b[32m    943\u001b[39m     method,\n\u001b[32m    944\u001b[39m     url,\n\u001b[32m   (...)\u001b[39m\u001b[32m    957\u001b[39m     **response_kw,\n\u001b[32m    958\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/bt4222grp9/.venv/lib/python3.13/site-packages/urllib3/util/retry.py:359\u001b[39m, in \u001b[36mRetry.sleep\u001b[39m\u001b[34m(self, response)\u001b[39m\n\u001b[32m    350\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Sleep between retry attempts.\u001b[39;00m\n\u001b[32m    351\u001b[39m \n\u001b[32m    352\u001b[39m \u001b[33;03mThis method will respect a server's ``Retry-After`` response header\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    355\u001b[39m \u001b[33;03mthis method will return immediately.\u001b[39;00m\n\u001b[32m    356\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    358\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.respect_retry_after_header \u001b[38;5;129;01mand\u001b[39;00m response:\n\u001b[32m--> \u001b[39m\u001b[32m359\u001b[39m     slept = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msleep_for_retry\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    360\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m slept:\n\u001b[32m    361\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/bt4222grp9/.venv/lib/python3.13/site-packages/urllib3/util/retry.py:338\u001b[39m, in \u001b[36mRetry.sleep_for_retry\u001b[39m\u001b[34m(self, response)\u001b[39m\n\u001b[32m    336\u001b[39m retry_after = \u001b[38;5;28mself\u001b[39m.get_retry_after(response)\n\u001b[32m    337\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m retry_after:\n\u001b[32m--> \u001b[39m\u001b[32m338\u001b[39m     \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_after\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    339\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    341\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import requests\n",
    "import spotipy\n",
    "import time\n",
    "import logging\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "from dotenv import load_dotenv\n",
    "from tqdm import tqdm  # For progress tracking\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 1. Configure Logging\n",
    "# ------------------------------------------------------------------------------\n",
    "logging.basicConfig(\n",
    "    filename=\"spotify_extraction.log\",\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 2. Load Environment Variables & Authenticate with Spotify\n",
    "# ------------------------------------------------------------------------------\n",
    "load_dotenv()\n",
    "# Use environment variables if available. Otherwise, you can hardcode your credentials.\n",
    "SPOTIPY_CLIENT_ID = os.getenv(\"SPOTIPY_CLIENT_ID\")\n",
    "SPOTIPY_CLIENT_SECRET = os.getenv(\"SPOTIPY_CLIENT_SECRET\")\n",
    "print(SPOTIPY_CLIENT_ID)\n",
    "print(SPOTIPY_CLIENT_SECRET)\n",
    "if not SPOTIPY_CLIENT_ID or not SPOTIPY_CLIENT_SECRET:\n",
    "    raise Exception(\"Spotify credentials are missing. Check your .env file.\")\n",
    "\n",
    "sp = spotipy.Spotify(auth_manager=SpotifyClientCredentials(\n",
    "    client_id=SPOTIPY_CLIENT_ID,\n",
    "    client_secret=SPOTIPY_CLIENT_SECRET\n",
    "))\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 3. Load Dataset and Extract Unique Values\n",
    "# ------------------------------------------------------------------------------\n",
    "# Adjust the path to your dataset file as needed\n",
    "df = pd.read_parquet(r\"/Users/xavierhua/Documents/GitHub/bt4222grp9/preliminary datasets/all_songs_with_or_without_lyrics.parquet\")\n",
    "track_uris = df[\"track_uri\"].dropna().unique().tolist()\n",
    "album_names = df[\"album_name\"].dropna().unique().tolist()\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 4. Define Paths for Caching Progress\n",
    "# ------------------------------------------------------------------------------\n",
    "TRACK_PROGRESS_FILE = \"track_popularity_progress.pkl\"\n",
    "ALBUM_PROGRESS_FILE = \"album_release_progress.pkl\"\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 5. Helper Functions for Caching and URI Conversion\n",
    "# ------------------------------------------------------------------------------\n",
    "def load_progress(file_path):\n",
    "    \"\"\"Loads saved progress to avoid redundant API calls.\"\"\"\n",
    "    if os.path.exists(file_path) and os.path.getsize(file_path) > 0:\n",
    "        with open(file_path, \"rb\") as f:\n",
    "            return pickle.load(f)\n",
    "    return {}\n",
    "\n",
    "def extract_track_id(uri):\n",
    "    \"\"\"Extracts track ID from a Spotify URI (e.g. 'spotify:track:TRACK_ID').\"\"\"\n",
    "    parts = uri.split(\":\")\n",
    "    return parts[2] if len(parts) == 3 else uri\n",
    "\n",
    "# Convert track URIs to track IDs so that keys match the API responses\n",
    "track_ids = [extract_track_id(uri) for uri in track_uris]\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 6. Load Previous Progress (if available)\n",
    "# ------------------------------------------------------------------------------\n",
    "track_popularity_dict = load_progress(TRACK_PROGRESS_FILE)\n",
    "album_release_dict = load_progress(ALBUM_PROGRESS_FILE)\n",
    "\n",
    "logging.info(f\"Total unique tracks: {len(track_ids)} | Already processed: {len(track_popularity_dict)}\")\n",
    "logging.info(f\"Total unique albums: {len(album_names)} | Already processed: {len(album_release_dict)}\")\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 7. Define Functions to Fetch Data from Spotify with Rate Limit Handling\n",
    "# ------------------------------------------------------------------------------\n",
    "def fetch_track_popularity(track_batch):\n",
    "    \"\"\"Fetches track popularity scores from Spotify for a batch of track IDs.\"\"\"\n",
    "    while True:\n",
    "        try:\n",
    "            response = sp.tracks(track_batch)\n",
    "            # Response keys are track IDs and popularity scores\n",
    "            return {track[\"id\"]: track[\"popularity\"] for track in response[\"tracks\"] if track}\n",
    "        except spotipy.SpotifyException as e:\n",
    "            if e.http_status == 429:\n",
    "                retry_after = int(e.headers.get(\"Retry-After\", 5))\n",
    "                logging.warning(f\"Rate limit hit. Retrying track popularity after {retry_after} seconds...\")\n",
    "                time.sleep(retry_after)\n",
    "            else:\n",
    "                logging.error(f\"Error fetching track popularity: {e}\")\n",
    "                return {}\n",
    "\n",
    "def fetch_album_release(album_batch):\n",
    "    \"\"\"\n",
    "    Fetches album release dates from Spotify for a list of album names.\n",
    "\n",
    "    1. For each album name, searches Spotify (limit=1).\n",
    "    2. If found, retrieves the album ID.\n",
    "    3. Calls sp.album(album_id) to get the official album details (including release_date).\n",
    "    4. Returns a dict {album_name_in_spotify: release_date} for each album in the batch.\n",
    "\n",
    "    NOTE: Searching by album name alone can be ambiguous. If you have the album ID or artist info,\n",
    "          you should refine the search or directly call sp.album(album_id).\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    for album_name in album_batch:\n",
    "        while True:\n",
    "            try:\n",
    "                # Step 1: Search by album name\n",
    "                search_results = sp.search(q=f\"album:{album_name}\", type=\"album\", limit=1)\n",
    "                items = search_results[\"albums\"][\"items\"]\n",
    "                if items:\n",
    "                    # Step 2: Retrieve the album ID\n",
    "                    album_id = items[0][\"id\"]\n",
    "\n",
    "                    # Step 3: Get full album details from the official 'Get an Album' endpoint\n",
    "                    album_data = sp.album(album_id)\n",
    "\n",
    "                    # Step 4: Store the release_date in the results dict\n",
    "                    #   album_data[\"name\"] is Spotify's canonical album title\n",
    "                    #   album_data[\"release_date\"] is the official release date\n",
    "                    results[album_data[\"name\"]] = album_data[\"release_date\"]\n",
    "                else:\n",
    "                    # If no search results, store None or empty\n",
    "                    results[album_name] = None\n",
    "\n",
    "                # Break out of the while-loop once we've processed this album_name\n",
    "                break\n",
    "\n",
    "            except spotipy.SpotifyException as e:\n",
    "                if e.http_status == 429:\n",
    "                    # Handle rate limit\n",
    "                    retry_after = int(e.headers.get(\"Retry-After\", 5))\n",
    "                    logging.warning(f\"Rate limit hit. Retrying after {retry_after} seconds...\")\n",
    "                    time.sleep(retry_after)\n",
    "                else:\n",
    "                    # Log any other SpotifyException, skip this album\n",
    "                    logging.error(f\"SpotifyException fetching release date for '{album_name}': {e}\")\n",
    "                    results[album_name] = None\n",
    "                    break\n",
    "\n",
    "            except requests.exceptions.ReadTimeout:\n",
    "                # If there's a timeout, log and skip this album\n",
    "                logging.error(f\"ReadTimeout fetching release date for '{album_name}'. Skipping.\")\n",
    "                results[album_name] = None\n",
    "                break\n",
    "\n",
    "            except requests.exceptions.RequestException as re:\n",
    "                # Other network-related errors\n",
    "                logging.error(f\"RequestException fetching release date for '{album_name}': {re}\")\n",
    "                results[album_name] = None\n",
    "                break\n",
    "\n",
    "            except Exception as ex:\n",
    "                # Catch-all for unexpected errors\n",
    "                logging.error(f\"Unexpected error for album '{album_name}': {ex}\")\n",
    "                results[album_name] = None\n",
    "                break\n",
    "\n",
    "    return results\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 8. Process Track Popularity in Batches (Resuming from Last Progress)\n",
    "# ------------------------------------------------------------------------------\n",
    "# Create batches of track IDs (50 per batch)\n",
    "track_batches = [track_ids[i:i+50] for i in range(0, len(track_ids), 50)]\n",
    "# Only process batches that are not fully in the saved dictionary\n",
    "remaining_track_batches = [batch for batch in track_batches if not set(batch).issubset(track_popularity_dict.keys())]\n",
    "\n",
    "logging.info(f\"Starting track popularity extraction | Remaining batches: {len(remaining_track_batches)}\")\n",
    "for batch in tqdm(remaining_track_batches, desc=\"Fetching Track Popularity\"):\n",
    "    track_popularity_dict.update(fetch_track_popularity(batch))\n",
    "    # Save progress every 500 records processed\n",
    "    if len(track_popularity_dict) % 500 < 50:  # when crossing multiples of 500\n",
    "        with open(TRACK_PROGRESS_FILE, \"wb\") as f:\n",
    "            pickle.dump(track_popularity_dict, f)\n",
    "        logging.info(f\"Saved track popularity progress at {len(track_popularity_dict)} records.\")\n",
    "\n",
    "# Final save for track popularity progress\n",
    "with open(TRACK_PROGRESS_FILE, \"wb\") as f:\n",
    "    pickle.dump(track_popularity_dict, f)\n",
    "logging.info(f\"Final track popularity progress saved: {len(track_popularity_dict)} records.\")\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 9. Process Album Release Dates in Batches (Resuming from Last Progress)\n",
    "# ------------------------------------------------------------------------------\n",
    "# Create batches of album names (20 per batch)\n",
    "album_batches = [album_names[i:i+20] for i in range(0, len(album_names), 20)]\n",
    "remaining_album_batches = [batch for batch in album_batches if not set(batch).issubset(album_release_dict.keys())]\n",
    "\n",
    "logging.info(f\"Starting album release extraction | Remaining batches: {len(remaining_album_batches)}\")\n",
    "for batch in tqdm(remaining_album_batches, desc=\"Fetching Album Release Dates\"):\n",
    "    album_release_dict.update(fetch_album_release(batch))\n",
    "    # Save progress every 100 records processed\n",
    "    if len(album_release_dict) % 100 < 20:  # when crossing multiples of 100\n",
    "        with open(ALBUM_PROGRESS_FILE, \"wb\") as f:\n",
    "            pickle.dump(album_release_dict, f)\n",
    "        logging.info(f\"Saved album release progress at {len(album_release_dict)} records.\")\n",
    "\n",
    "# Final save for album release dates progress\n",
    "with open(ALBUM_PROGRESS_FILE, \"wb\") as f:\n",
    "    pickle.dump(album_release_dict, f)\n",
    "logging.info(f\"Final album release progress saved: {len(album_release_dict)} records.\")\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 10. Merge Fetched Data into Dataset and Export CSV Files\n",
    "# ------------------------------------------------------------------------------\n",
    "# Map track popularity by matching track IDs to the dataset’s track_uri (converted to IDs)\n",
    "df[\"track_popularity\"] = df[\"track_uri\"].apply(lambda uri: track_popularity_dict.get(extract_track_id(uri)))\n",
    "df[\"album_release_date\"] = df[\"album_name\"].map(album_release_dict)\n",
    "\n",
    "# Save CSV files (dropping rows with missing data in the respective columns)\n",
    "df[[\"track_uri\", \"track_popularity\"]].dropna().to_csv(\"track_popularity.csv\", index=False)\n",
    "df[[\"album_name\", \"album_release_date\"]].dropna().to_csv(\"album_release_dates.csv\", index=False)\n",
    "\n",
    "logging.info(\"Extraction complete! Two CSV files saved: 'track_popularity.csv' and 'album_release_dates.csv'\")\n",
    "print(\"Extraction complete! Check logs for detailed progress.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
