{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import logging\n",
    "import pickle\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from transformers import pipeline\n",
    "\n",
    "# -------------------------------\n",
    "# 1Ô∏è‚É£ Setup Logging\n",
    "# -------------------------------\n",
    "logging.basicConfig(format=\"%(asctime)s - %(levelname)s - %(message)s\", level=logging.INFO)\n",
    "\n",
    "# -------------------------------\n",
    "# 2Ô∏è‚É£ Load Dataset & Preprocess Lyrics\n",
    "# -------------------------------\n",
    "logging.info(\"üîπ Loading dataset...\")\n",
    "df = pd.read_parquet(\"/Users/xavierhua/Documents/GitHub/bt4222grp9/phase2_data_cleaning/cleaned dataset/track_cleaned.parquet\")\n",
    "if \"lyrics\" not in df.columns:\n",
    "    raise ValueError(\"‚ùå The dataset must contain a 'lyrics' column.\")\n",
    "\n",
    "df = df.dropna(subset=[\"lyrics\"])\n",
    "df = df[~df[\"lyrics\"].isin([\"No Lyrics\", \"none\", \"None\"])].copy()\n",
    "\n",
    "lyrics_list = df[\"lyrics\"].tolist()\n",
    "track_idx_list = df[\"track_idx\"].tolist()\n",
    "logging.info(f\"‚úÖ Using {len(df)} valid lyrics for Zero-Shot Classification.\")\n",
    "\n",
    "# -------------------------------\n",
    "# 3Ô∏è‚É£ Load Zero-Shot Classification Model\n",
    "# -------------------------------\n",
    "logging.info(\"üîπ Loading Zero-Shot Classifier...\")\n",
    "device = 0 if torch.cuda.is_available() else -1\n",
    "model_name = \"MoritzLaurer/mDeBERTa-v3-base-mnli-xnli\"\n",
    "classifier = pipeline(\n",
    "    \"zero-shot-classification\",\n",
    "    model=model_name,\n",
    "    device=device,\n",
    "    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
    ")\n",
    "\n",
    "emotions = [\"joy\", \"calm\", \"sadness\", \"fear\", \"energizing\", \"dreamy\"]\n",
    "\n",
    "# -------------------------------\n",
    "# 4Ô∏è‚É£ Checkpoint Setup\n",
    "# -------------------------------\n",
    "checkpoint_path = \"classification_checkpoint.pkl\"\n",
    "start_idx = 0\n",
    "emotion_scores = {emotion: [] for emotion in emotions}\n",
    "track_ids = []\n",
    "\n",
    "if os.path.exists(checkpoint_path):\n",
    "    logging.info(\"üîÑ Resuming from last checkpoint...\")\n",
    "    with open(checkpoint_path, \"rb\") as f:\n",
    "        saved_data = pickle.load(f)\n",
    "        start_idx = saved_data[\"last_processed_idx\"]\n",
    "        emotion_scores = saved_data[\"emotion_scores\"]\n",
    "        track_ids = saved_data[\"track_ids\"]\n",
    "\n",
    "logging.info(f\"üîπ Resuming from index {start_idx} / {len(lyrics_list)}\")\n",
    "\n",
    "# -------------------------------\n",
    "# 5Ô∏è‚É£ Batched Zero-Shot Classification\n",
    "# -------------------------------\n",
    "batch_size_classify = 32  # Increase batch size if possible\n",
    "logging.info(\"üîπ Running Zero-Shot Classification...\")\n",
    "\n",
    "batches_processed = 0\n",
    "for i in tqdm(range(start_idx, len(lyrics_list), batch_size_classify), desc=\"Classifying Emotions\"):\n",
    "    batch_lyrics = lyrics_list[i:i + batch_size_classify]\n",
    "    batch_track_ids = track_idx_list[i:i + batch_size_classify]\n",
    "    \n",
    "    batch_results = classifier(batch_lyrics, candidate_labels=emotions, multi_label=True)\n",
    "    if isinstance(batch_results, dict):\n",
    "        batch_results = [batch_results]\n",
    "\n",
    "    for idx, result in enumerate(batch_results):\n",
    "        track_ids.append(batch_track_ids[idx])\n",
    "        scores_dict = dict(zip(result[\"labels\"], result[\"scores\"]))\n",
    "        for emotion in emotions:\n",
    "            emotion_scores[emotion].append(scores_dict.get(emotion, 0.0))\n",
    "    \n",
    "    batches_processed += 1\n",
    "    if batches_processed % 2 == 0:  # Adjust frequency as needed\n",
    "        with open(checkpoint_path, \"wb\") as f:\n",
    "            pickle.dump({\n",
    "                \"last_processed_idx\": i + batch_size_classify,\n",
    "                \"emotion_scores\": emotion_scores,\n",
    "                \"track_ids\": track_ids\n",
    "            }, f)\n",
    "        logging.info(f\"üíæ Checkpoint saved at index {i + batch_size_classify}\")\n",
    "\n",
    "logging.info(\"‚úÖ Classification complete. Saving results...\")\n",
    "\n",
    "# -------------------------------\n",
    "# 6Ô∏è‚É£ Save Results\n",
    "# -------------------------------\n",
    "min_length = min(len(track_ids), *[len(scores) for scores in emotion_scores.values()])\n",
    "track_ids = track_ids[:min_length]\n",
    "emotion_scores = {k: v[:min_length] for k, v in emotion_scores.items()}\n",
    "\n",
    "output_df = pd.DataFrame({\n",
    "    \"track_idx\": track_ids,\n",
    "    **emotion_scores\n",
    "})\n",
    "output_df = output_df.drop_duplicates(subset=[\"track_idx\"], keep=\"first\")\n",
    "output_df.to_csv(\"full_dataset_emotion_scores.csv\", index=False)\n",
    "\n",
    "if os.path.exists(checkpoint_path):\n",
    "    os.remove(checkpoint_path)\n",
    "\n",
    "logging.info(\"‚úÖ Full dataset emotion scores saved as 'full_dataset_emotion_scores.csv'.\")\n",
    "print(\"‚úÖ Emotion classification complete! Results saved.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
